{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oImTwratdWNj"
      },
      "source": [
        "# ðŸ§ ðŸŽ¥ Agentic AI Demo: Writer Agent + Video Generator Agent\n",
        "\n",
        "This Google Colab notebook demonstrates an agentic AI setup with two agents:\n",
        "\n",
        "1. **Writer Agent** (OpenAI GPT-4): Takes a user-provided topic and generates a creative video prompt.\n",
        "2. **Video Generator Agent** (FAL.AI): Takes the generated prompt and creates a video using fal.ai's API.\n",
        "\n",
        "Make sure you have API keys for both OpenAI and fal.ai."
      ],
      "id": "oImTwratdWNj"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nhJXE-LFdWNl",
        "outputId": "ae550b2d-3b71-4f12-823f-7c95b145a389"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.11/dist-packages (1.93.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (2.32.3)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.10.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from openai) (2.11.7)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.11/dist-packages (from openai) (4.14.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests) (2025.6.15)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.4.1)\n"
          ]
        }
      ],
      "source": [
        "# âœ… Setup: Install required packages\n",
        "!pip install openai requests"
      ],
      "id": "nhJXE-LFdWNl"
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install fal-client"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WS2us7r5m-wx",
        "outputId": "a8b96d80-3a9f-443d-e594-bd64f4d30d02"
      },
      "id": "WS2us7r5m-wx",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting fal-client\n",
            "  Downloading fal_client-0.7.0-py3-none-any.whl.metadata (3.5 kB)\n",
            "Requirement already satisfied: httpx<1,>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from fal-client) (0.28.1)\n",
            "Collecting httpx-sse<0.5,>=0.4.0 (from fal-client)\n",
            "  Downloading httpx_sse-0.4.1-py3-none-any.whl.metadata (9.4 kB)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.21.0->fal-client) (4.9.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.21.0->fal-client) (2025.6.15)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.21.0->fal-client) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.21.0->fal-client) (3.10)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.21.0->fal-client) (0.16.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.21.0->fal-client) (1.3.1)\n",
            "Requirement already satisfied: typing_extensions>=4.5 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.21.0->fal-client) (4.14.0)\n",
            "Downloading fal_client-0.7.0-py3-none-any.whl (10 kB)\n",
            "Downloading httpx_sse-0.4.1-py3-none-any.whl (8.1 kB)\n",
            "Installing collected packages: httpx-sse, fal-client\n",
            "Successfully installed fal-client-0.7.0 httpx-sse-0.4.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zgDATpgvnjFR"
      },
      "id": "zgDATpgvnjFR",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "npMNduvsdWNm"
      },
      "outputs": [],
      "source": [
        "from google.colab import userdata\n",
        "\n",
        "# âœ… API Keys\n",
        "client = OpenAI(api_key=userdata.get('openai_api_key'))\n",
        "# FAL_API_KEY = userdata.get('fal_api')        # Replace this with your fal.ai API key\n",
        "import os\n",
        "os.environ['FAL_KEY'] = userdata.get('fal_api')"
      ],
      "id": "npMNduvsdWNm"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lVdzcAgsdWNm",
        "outputId": "379996ff-f6c4-4340-89c7-09b592359f0d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated Video Prompt:\n",
            " Title: \"Paradise Reclaimed: The Epoch of Sustainable Cities\"\n",
            "\n",
            "Begin with an overlooking aerial view of a bustling, smog-filled city, cars crowding the streets, and high-rise buildings boxing in the sky. Suddenly, the scene fades into a white canvas. \n",
            "\n",
            "Now slowly, sketch lines materialize. They carve out sprawling parks seeping into the heart of the city, buildings covered in a layer of greenery, roads replaced with waterways, solar panels and wind turbines sprinkled generously across the skyline. \n",
            "\n",
            "Cut to ground-level, zoom into a typical day where people commute in solar-powered public transport and personal electric vehicles. Pedestrians can be seen enjoying walking, cycling or e-scooting on clean pathways, their faces exuding happiness. Drift over urban farms producing fresh produce mid-city, delivering it straight to local markets and homes.\n",
            "\n",
            "Focus next on an eco-school, where the children are learning sustainability practices in a touch-and-learn garden setting. Nearby, a power plant where waste is converted into energy for local use glistens in the sunlight. Pan over to architecturally advanced buildings having in-built water recycling systems, and green terraces bustling with community gatherings.\n",
            "\n",
            "The scene transitions from day to night, showcasing smart street lights shimmering on renewable energy, the skyline filled with energy-efficient buildings lit up under the starlit sky. \n",
            "\n",
            "Show snippets of a futuristic city in harmony with nature and technology, designed smartly to adapt to climate change, and resilient to natural disasters. End with scenes of vibrant local life, thriving nature, and clean energy sources against the canvas of a perfectly sustainable city.\n",
            "\n",
            "A voiceover concludes, \"we believe in the future of sustainable cities, a place where the human spirit and nature co-exist with grace and respect. This is our gift to the future generations.\"\n",
            "\n",
            "Fade out, with a question lingers on: \"Are you ready to join us on this voyage towards the sustainable cities of tomorrow?\"\n"
          ]
        }
      ],
      "source": [
        "# âœ… Writer Agent: Generate video prompt from topic\n",
        "from openai import OpenAI\n",
        "\n",
        "openai.api_key = OPENAI_API_KEY\n",
        "\n",
        "def generate_video_prompt(topic):\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"gpt-4\",\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"You are a creative scriptwriter for short AI-generated videos.\"},\n",
        "            {\"role\": \"user\", \"content\": f\"Write a visual and engaging prompt for a short video about: {topic}\"}\n",
        "        ]\n",
        "    )\n",
        "    return response.choices[0].message.content.strip()\n",
        "\n",
        "# ðŸ”½ Example\n",
        "topic = \"The future of sustainable cities\"\n",
        "video_prompt = generate_video_prompt(topic)\n",
        "print(\"Generated Video Prompt:\\n\", video_prompt)"
      ],
      "id": "lVdzcAgsdWNm"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QYJMjGlQdWNm",
        "outputId": "fde094b1-84d3-45c9-f18e-2e4625236194"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ðŸŽ¬ Generated Video URL:\n",
            " https://v3.fal.media/files/koala/isl6ur1KJGTSsfH1tp2li_output.mp4\n"
          ]
        }
      ],
      "source": [
        "# âœ… Video Generator Agent: Veo 3 via fal_client\n",
        "import fal_client\n",
        "\n",
        "# Optional: show progress while waiting\n",
        "def on_queue_update(update):\n",
        "    if isinstance(update, fal_client.InProgress):\n",
        "        for log in update.logs:\n",
        "            print(log[\"message\"])\n",
        "\n",
        "def generate_veo3_video(prompt):\n",
        "    result = fal_client.subscribe(\n",
        "        \"fal-ai/veo3\",\n",
        "        arguments={\n",
        "            \"prompt\": prompt,\n",
        "            \"aspect_ratio\": \"16:9\",         # Optional: 16:9, 9:16, or 1:1\n",
        "            \"duration\": \"8s\",               # Optional: 8s\n",
        "            \"enhance_prompt\": True,         # Optional: Better visuals\n",
        "            \"generate_audio\": True          # Optional: Include AI audio\n",
        "        },\n",
        "        with_logs=True,\n",
        "        on_queue_update=on_queue_update    # Optional: stream logs\n",
        "    )\n",
        "    return result.get(\"video\", {}).get(\"url\")\n",
        "\n",
        "# ðŸ”½ Generate video using Veo3\n",
        "video_url = generate_veo3_video(video_prompt)\n",
        "print(\"\\nðŸŽ¬ Generated Video URL:\\n\", video_url)\n"
      ],
      "id": "QYJMjGlQdWNm"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "id": "50b70430",
        "outputId": "6dd74fab-4df6-4e4f-ff14-4c1af7ae3969"
      },
      "source": [
        "export FAL_KEY=userdata.get('fal_api')"
      ],
      "id": "50b70430",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "invalid syntax (ipython-input-17-3948938004.py, line 1)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipython-input-17-3948938004.py\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    export FAL_KEY=userdata.get('fal_api')\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    }
  ]
}